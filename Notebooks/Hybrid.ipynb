{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "import joblib\n",
    "import os\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "data=pd.read_csv('../data_store/final_data/final_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Random Forest model...\n",
      "\n",
      "Training LSTM model...\n",
      "Epoch [10/50], Train Loss: 0.0274, Val Loss: 0.0235\n",
      "Epoch [20/50], Train Loss: 0.0273, Val Loss: 0.0236\n",
      "Epoch [30/50], Train Loss: 0.0267, Val Loss: 0.0237\n",
      "Epoch [40/50], Train Loss: 0.0235, Val Loss: 0.0238\n",
      "Epoch [50/50], Train Loss: 0.0235, Val Loss: 0.0237\n",
      "\n",
      "Making final predictions...\n",
      "\n",
      "Hybrid Model Performance Metrics:\n",
      "\n",
      "Training Metrics:\n",
      "R² Score: 1.0000\n",
      "RMSE: 0.1515\n",
      "MAE: 0.0822\n",
      "\n",
      "Test Metrics:\n",
      "R² Score: 0.9999\n",
      "RMSE: 0.3206\n",
      "MAE: 0.1632\n",
      "\n",
      "Results have been saved to:\n",
      "- aqi_predictions.csv (predictions)\n",
      "- model_metrics.json (performance metrics)\n",
      "- lstm_losses.png (loss curves)\n",
      "- feature_importance.png (Random Forest feature importance)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Prepare features and target\n",
    "feature_cols = ['co', 'no', 'no2', 'o3', 'so2', 'pm2_5', 'pm10', 'nh3', \n",
    "                'temperature_2m', 'relative_humidity_2m', 'rain', \n",
    "                'wind_speed_10m', 'wind_direction_10m', \n",
    "                'soil_temperature_0_to_7cm', 'soil_moisture_0_to_7cm']\n",
    "\n",
    "X = data[feature_cols]\n",
    "y = data['aqi']\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Scale the features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Train Random Forest model\n",
    "print(\"Training Random Forest model...\")\n",
    "rf_model = RandomForestRegressor(\n",
    "    n_estimators=200,\n",
    "    max_depth=20,\n",
    "    min_samples_split=5,\n",
    "    n_jobs=-1,\n",
    "    random_state=42\n",
    ")\n",
    "rf_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "os.makedirs('models', exist_ok=True)\n",
    "with open('models/random_forest.pkl', 'wb') as f:\n",
    "    pickle.dump(rf_model, f)\n",
    "\n",
    "# Generate residuals using Random Forest model\n",
    "y_pred_train = rf_model.predict(X_train_scaled)\n",
    "y_pred_test = rf_model.predict(X_test_scaled)\n",
    "residuals_train = y_train - y_pred_train\n",
    "residuals_test = y_test - y_pred_test\n",
    "\n",
    "# LSTM Dataset\n",
    "class ResidualDataset(Dataset):\n",
    "    def __init__(self, features, residuals, sequence_length=24):\n",
    "        self.features = torch.FloatTensor(features)\n",
    "        self.residuals = torch.FloatTensor(residuals.values.reshape(-1, 1))\n",
    "        self.sequence_length = sequence_length\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.features) - self.sequence_length\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        X = self.features[idx:idx + self.sequence_length]\n",
    "        y = self.residuals[idx + self.sequence_length]\n",
    "        return X, y\n",
    "\n",
    "# LSTM Model\n",
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size=64, num_layers=2):\n",
    "        super(LSTMModel, self).__init__()\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, 1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        lstm_out, _ = self.lstm(x)\n",
    "        last_hidden = lstm_out[:, -1, :]\n",
    "        out = self.fc(last_hidden)\n",
    "        return out\n",
    "\n",
    "# Train LSTM with loss tracking\n",
    "def train_lstm(train_loader, val_loader, model, epochs=50):\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model = model.to(device)\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters())\n",
    "    \n",
    "    best_val_loss = float('inf')\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        for X_batch, y_batch in train_loader:\n",
    "            X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(X_batch)\n",
    "            loss = criterion(outputs, y_batch)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            train_loss += loss.item()\n",
    "        \n",
    "        avg_train_loss = train_loss / len(train_loader)\n",
    "        train_losses.append(avg_train_loss)\n",
    "            \n",
    "        # Validation\n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        with torch.no_grad():\n",
    "            for X_batch, y_batch in val_loader:\n",
    "                X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "                outputs = model(X_batch)\n",
    "                val_loss += criterion(outputs, y_batch).item()\n",
    "        \n",
    "        avg_val_loss = val_loss / len(val_loader)\n",
    "        val_losses.append(avg_val_loss)\n",
    "        \n",
    "        if avg_val_loss < best_val_loss:\n",
    "            best_val_loss = avg_val_loss\n",
    "            torch.save(model.state_dict(), 'best_lstm_model.pth')\n",
    "        \n",
    "        if (epoch + 1) % 10 == 0:\n",
    "            print(f'Epoch [{epoch+1}/{epochs}], Train Loss: {avg_train_loss:.4f}, Val Loss: {avg_val_loss:.4f}')\n",
    "    \n",
    "    return train_losses, val_losses\n",
    "\n",
    "# Create LSTM datasets\n",
    "sequence_length = 24  # 24 hours\n",
    "batch_size = 32\n",
    "\n",
    "train_dataset = ResidualDataset(X_train_scaled, residuals_train, sequence_length)\n",
    "test_dataset = ResidualDataset(X_test_scaled, residuals_test, sequence_length)\n",
    "\n",
    "train_size = int(0.8 * len(train_dataset))\n",
    "val_size = len(train_dataset) - train_size\n",
    "\n",
    "train_dataset, val_dataset = torch.utils.data.random_split(train_dataset, [train_size, val_size])\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size)\n",
    "\n",
    "# Initialize and train LSTM\n",
    "print(\"\\nTraining LSTM model...\")\n",
    "lstm_model = LSTMModel(input_size=len(feature_cols))\n",
    "train_losses, val_losses = train_lstm(train_loader, val_loader, lstm_model)\n",
    "\n",
    "# Plot training and validation losses\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(train_losses, label='Training Loss')\n",
    "plt.plot(val_losses, label='Validation Loss')\n",
    "plt.title('LSTM Training and Validation Losses')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.savefig('lstm_losses.png')\n",
    "plt.close()\n",
    "\n",
    "# Function to make hybrid predictions\n",
    "def make_hybrid_predictions(X, ml_model, lstm_model, sequence_length=24):\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    \n",
    "    # ML predictions\n",
    "    ml_pred = ml_model.predict(X)\n",
    "    \n",
    "    # Prepare data for LSTM\n",
    "    dataset = ResidualDataset(X, pd.Series(np.zeros(len(X))), sequence_length)\n",
    "    loader = DataLoader(dataset, batch_size=32)\n",
    "    \n",
    "    # LSTM predictions\n",
    "    lstm_model.eval()\n",
    "    lstm_preds = []\n",
    "    with torch.no_grad():\n",
    "        for X_batch, _ in loader:\n",
    "            X_batch = X_batch.to(device)\n",
    "            outputs = lstm_model(X_batch)\n",
    "            lstm_preds.extend(outputs.cpu().numpy())\n",
    "    \n",
    "    # Combine predictions\n",
    "    final_predictions = ml_pred[sequence_length:] + np.array(lstm_preds).flatten()\n",
    "    return final_predictions\n",
    "\n",
    "# Make predictions for both train and test sets\n",
    "print(\"\\nMaking final predictions...\")\n",
    "train_predictions = make_hybrid_predictions(X_train_scaled, rf_model, lstm_model)\n",
    "test_predictions = make_hybrid_predictions(X_test_scaled, rf_model, lstm_model)\n",
    "\n",
    "# Calculate metrics for both train and test sets\n",
    "train_metrics = {\n",
    "    'r2_score': r2_score(y_train[24:], train_predictions),\n",
    "    'rmse': np.sqrt(mean_squared_error(y_train[24:], train_predictions)),\n",
    "    'mae': mean_absolute_error(y_train[24:], train_predictions)\n",
    "}\n",
    "\n",
    "test_metrics = {\n",
    "    'r2_score': r2_score(y_test[24:], test_predictions),\n",
    "    'rmse': np.sqrt(mean_squared_error(y_test[24:], test_predictions)),\n",
    "    'mae': mean_absolute_error(y_test[24:], test_predictions)\n",
    "}\n",
    "\n",
    "# Print metrics\n",
    "print(\"\\nHybrid Model Performance Metrics:\")\n",
    "print(\"\\nTraining Metrics:\")\n",
    "print(f\"R² Score: {train_metrics['r2_score']:.4f}\")\n",
    "print(f\"RMSE: {train_metrics['rmse']:.4f}\")\n",
    "print(f\"MAE: {train_metrics['mae']:.4f}\")\n",
    "\n",
    "print(\"\\nTest Metrics:\")\n",
    "print(f\"R² Score: {test_metrics['r2_score']:.4f}\")\n",
    "print(f\"RMSE: {test_metrics['rmse']:.4f}\")\n",
    "print(f\"MAE: {test_metrics['mae']:.4f}\")\n",
    "\n",
    "# Plot feature importance\n",
    "feature_importance = pd.DataFrame({\n",
    "    'feature': feature_cols,\n",
    "    'importance': rf_model.feature_importances_\n",
    "})\n",
    "feature_importance = feature_importance.sort_values('importance', ascending=False)\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.bar(feature_importance['feature'], feature_importance['importance'])\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.title('Random Forest Feature Importance')\n",
    "plt.tight_layout()\n",
    "plt.savefig('feature_importance.png')\n",
    "plt.close()\n",
    "\n",
    "# Save predictions to CSV\n",
    "predictions_df = pd.DataFrame({\n",
    "    'timestamp': data.loc[y_test[24:].index, 'timestamp'].values,\n",
    "    'state': data.loc[y_test[24:].index, 'state'].values,\n",
    "    'actual_aqi': y_test[24:].values,\n",
    "    'predicted_aqi': test_predictions,\n",
    "    'absolute_error': np.abs(y_test[24:].values - test_predictions)\n",
    "})\n",
    "predictions_df.to_csv('aqi_predictions.csv', index=False)\n",
    "\n",
    "# Save metrics to JSON\n",
    "all_metrics = {\n",
    "    'train_metrics': train_metrics,\n",
    "    'test_metrics': test_metrics,\n",
    "    'feature_importance': feature_importance.to_dict(orient='records'),\n",
    "    'training_params': {\n",
    "        'sequence_length': sequence_length,\n",
    "        'batch_size': batch_size,\n",
    "        'feature_columns': feature_cols,\n",
    "        'rf_params': {\n",
    "            'n_estimators': 200,\n",
    "            'max_depth': 20,\n",
    "            'min_samples_split': 5\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "\n",
    "def load_models():\n",
    "    rf_model = pickle.load(open('models/random_forest.pkl', 'rb'))\n",
    "    lstm_model = LSTMModel(input_size=len(feature_cols))\n",
    "    lstm_model.load_state_dict(torch.load('models/lstm_model.pth'))\n",
    "    return rf_model, lstm_model\n",
    "\n",
    "with open('model_metrics.json', 'w') as f:\n",
    "    json.dump(all_metrics, f, indent=4)\n",
    "\n",
    "print(\"\\nResults have been saved to:\")\n",
    "print(\"- aqi_predictions.csv (predictions)\")\n",
    "print(\"- model_metrics.json (performance metrics)\")\n",
    "print(\"- lstm_losses.png (loss curves)\")\n",
    "print(\"- feature_importance.png (Random Forest feature importance)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PT_GPU",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
